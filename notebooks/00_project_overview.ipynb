{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb8112f",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Project Structure\n",
    "\n",
    "```\n",
    "assignment/\n",
    "â”œâ”€â”€ data/                    # Data processing modules\n",
    "â”‚   â”œâ”€â”€ dataset.py          # SQuAD dataset loader\n",
    "â”‚   â”œâ”€â”€ preprocessing.py    # Tokenization & metrics\n",
    "â”‚   â””â”€â”€ dataloader.py       # DataLoader utilities\n",
    "â”‚\n",
    "â”œâ”€â”€ training/                # Training infrastructure\n",
    "â”‚   â”œâ”€â”€ train.py            # Training loop\n",
    "â”‚   â””â”€â”€ evaluate.py         # Evaluation metrics\n",
    "â”‚\n",
    "â”œâ”€â”€ inference/               # Deployment\n",
    "â”‚   â””â”€â”€ predict.py          # QAPredictor class\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks/               # Jupyter notebooks\n",
    "â”‚   â”œâ”€â”€ 00_project_overview.ipynb      # This notebook\n",
    "â”‚   â”œâ”€â”€ 01_data_exploration.ipynb      # Dataset analysis\n",
    "â”‚   â”œâ”€â”€ 02_tokenizer_testing.ipynb     # Tokenization\n",
    "â”‚   â”œâ”€â”€ 03_data_validation.ipynb       # Preprocessing validation\n",
    "â”‚   â”œâ”€â”€ 04_model_training.ipynb        # Training workflow\n",
    "â”‚   â”œâ”€â”€ 05_evaluation_analysis.ipynb   # Evaluation\n",
    "â”‚   â””â”€â”€ 06_deployment.ipynb            # Gradio demo\n",
    "â”‚\n",
    "â”œâ”€â”€ config.py                # Configuration\n",
    "â”œâ”€â”€ requirements.txt         # Dependencies\n",
    "â”œâ”€â”€ app.py                   # Standalone Gradio app\n",
    "â””â”€â”€ README.md               # Documentation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3ac5b",
   "metadata": {},
   "source": [
    "## ðŸš€ Quick Start Guide\n",
    "\n",
    "### 1. Install Dependencies\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 2. Run Notebooks in Order\n",
    "\n",
    "| Notebook | Purpose | Time Required |\n",
    "|----------|---------|---------------|\n",
    "| `01_data_exploration.ipynb` | Explore SQuAD dataset | 5 min |\n",
    "| `02_tokenizer_testing.ipynb` | Understand BERT tokenization | 5 min |\n",
    "| `03_data_validation.ipynb` | Validate preprocessing | 10 min |\n",
    "| `04_model_training.ipynb` | Train BERT-QA model | 2-3 hours |\n",
    "| `05_evaluation_analysis.ipynb` | Evaluate performance | 15 min |\n",
    "| `06_deployment.ipynb` | Deploy interactive demo | 5 min |\n",
    "\n",
    "### 3. Launch Deployment\n",
    "```bash\n",
    "python app.py\n",
    "```\n",
    "Access at: http://127.0.0.1:7860"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627128e",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Key Concepts\n",
    "\n",
    "### What is Extractive Question Answering?\n",
    "\n",
    "Given a **question** and a **context** paragraph, the model extracts the exact answer span from the context.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Question: What is the capital of France?\n",
    "Context:  Paris is the capital and most populous city of France.\n",
    "Answer:   Paris\n",
    "```\n",
    "\n",
    "### How BERT Works for QA\n",
    "\n",
    "1. **Input Format:** `[CLS] question [SEP] context [SEP]`\n",
    "2. **BERT Encoding:** 12 transformer layers process the sequence\n",
    "3. **QA Head:** Two linear layers predict start/end positions\n",
    "4. **Output:** Token positions of the answer span\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "**Exact Match (EM):**\n",
    "- Binary score: 1 if prediction exactly matches ground truth (after normalization), 0 otherwise\n",
    "- Strict metric for perfect answers\n",
    "\n",
    "**F1 Score:**\n",
    "- Token-level overlap between prediction and ground truth\n",
    "- Partial credit for incomplete answers\n",
    "- Computed as: F1 = 2 Ã— (precision Ã— recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb45fd",
   "metadata": {},
   "source": [
    "## ðŸ“Š Dataset Overview\n",
    "\n",
    "### SQuAD v1.1 (Stanford Question Answering Dataset)\n",
    "\n",
    "- **Training Set:** 87,599 questions\n",
    "- **Dev Set:** 10,570 questions\n",
    "- **Source:** Wikipedia articles\n",
    "- **Format:** JSON with titles, paragraphs, questions, and answers\n",
    "\n",
    "### Data Statistics\n",
    "\n",
    "- Average context length: ~120 words\n",
    "- Average question length: ~10 words\n",
    "- Average answer length: ~3 words\n",
    "- Question types: What (40%), Who (12%), How (10%), When (8%), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df7a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Quick check of dataset availability\n",
    "train_file = Path('../archive/train-v1.1.json')\n",
    "dev_file = Path('../archive/dev-v1.1.json')\n",
    "\n",
    "print(\"Dataset Files:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train: {'âœ“' if train_file.exists() else 'âœ—'} {train_file}\")\n",
    "print(f\"Dev:   {'âœ“' if dev_file.exists() else 'âœ—'} {dev_file}\")\n",
    "\n",
    "if train_file.exists():\n",
    "    with open(train_file, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    total_questions = sum(\n",
    "        len(qa['qas']) \n",
    "        for article in train_data['data'] \n",
    "        for qa in article['paragraphs']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTotal training questions: {total_questions:,}\")\n",
    "    print(f\"Total articles: {len(train_data['data']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd5cf3",
   "metadata": {},
   "source": [
    "## ðŸ”§ Configuration\n",
    "\n",
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: {config.model.model_name}\")\n",
    "print(f\"Max Length: {config.model.max_length}\")\n",
    "print(f\"Stride: {config.model.stride}\")\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Epochs: {config.training.epochs}\")\n",
    "print(f\"Batch Size: {config.training.batch_size}\")\n",
    "print(f\"Learning Rate: {config.training.learning_rate}\")\n",
    "print(f\"Warmup Ratio: {config.training.warmup_ratio}\")\n",
    "print(f\"Mixed Precision (FP16): {config.training.fp16}\")\n",
    "\n",
    "print(\"\\nData Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train File: {config.data.train_file}\")\n",
    "print(f\"Dev File: {config.data.dev_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dac84a",
   "metadata": {},
   "source": [
    "## ðŸ§ª Quick Test: Load and Predict (if model exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.predict import QAPredictor\n",
    "\n",
    "model_path = '../checkpoints/best_model.pt'\n",
    "\n",
    "if Path(model_path).exists():\n",
    "    print(\"âœ“ Trained model found! Loading predictor...\\n\")\n",
    "    predictor = QAPredictor(model_path)\n",
    "    \n",
    "    # Test prediction\n",
    "    context = \"\"\"Paris is the capital and most populous city of France. The city has an area \n",
    "    of 105 square kilometers and a population of 2,206,488 inhabitants.\"\"\"\n",
    "    \n",
    "    question = \"What is the capital of France?\"\n",
    "    \n",
    "    result = predictor.predict(question, context)\n",
    "    \n",
    "    print(\"Sample Prediction:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.1f}%\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"âœ— No trained model found.\")\n",
    "    print(\"\\nTo train the model, run: notebooks/04_model_training.ipynb\")\n",
    "    print(\"Expected training time: 2-3 hours on GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb8dec",
   "metadata": {},
   "source": [
    "## ðŸ“ Notebook Descriptions\n",
    "\n",
    "### Part 1: Data Understanding\n",
    "\n",
    "**01_data_exploration.ipynb**\n",
    "- Load and parse SQuAD JSON files\n",
    "- Analyze dataset structure and statistics\n",
    "- Visualize question/answer distributions\n",
    "- Identify question types\n",
    "\n",
    "**02_tokenizer_testing.ipynb**\n",
    "- Understand BERT tokenization\n",
    "- Learn about special tokens ([CLS], [SEP])\n",
    "- Explore offset_mapping for character-to-token conversion\n",
    "- Test stride handling for long contexts\n",
    "\n",
    "### Part 2: Data Preprocessing\n",
    "\n",
    "**03_data_validation.ipynb**\n",
    "- Validate SQuADDataset implementation\n",
    "- Test tokenization and answer span extraction\n",
    "- Verify DataLoader batching\n",
    "- Analyze answer position distributions\n",
    "- Measure extraction accuracy (~95%+)\n",
    "\n",
    "### Part 3: Model Training\n",
    "\n",
    "**04_model_training.ipynb**\n",
    "- Initialize BERT-QA model\n",
    "- Configure trainer with optimizers and schedulers\n",
    "- Train for 3 epochs with validation\n",
    "- Save best checkpoint\n",
    "- Monitor training/validation loss\n",
    "\n",
    "### Part 4: Evaluation & Deployment\n",
    "\n",
    "**05_evaluation_analysis.ipynb**\n",
    "- Load best model checkpoint\n",
    "- Compute EM and F1 on dev set\n",
    "- Analyze performance by question type\n",
    "- Error analysis and visualization\n",
    "- Generate evaluation report\n",
    "\n",
    "**06_deployment.ipynb**\n",
    "- Create interactive Gradio interface\n",
    "- Add example contexts and questions\n",
    "- Launch web demo\n",
    "- Export model to HuggingFace format\n",
    "- Generate standalone app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544d8fa",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By completing this project, you will learn:\n",
    "\n",
    "### Technical Skills\n",
    "1. **Data Processing**\n",
    "   - Parse complex JSON datasets\n",
    "   - Handle tokenization for transformer models\n",
    "   - Map character positions to token indices\n",
    "   - Implement sliding windows for long sequences\n",
    "\n",
    "2. **Model Training**\n",
    "   - Fine-tune pre-trained BERT models\n",
    "   - Use mixed precision training (FP16)\n",
    "   - Implement early stopping and checkpointing\n",
    "   - Monitor training with TensorBoard\n",
    "\n",
    "3. **Evaluation**\n",
    "   - Compute standard QA metrics (EM, F1)\n",
    "   - Analyze model errors\n",
    "   - Compare with baselines\n",
    "   - Generate evaluation reports\n",
    "\n",
    "4. **Deployment**\n",
    "   - Build interactive web interfaces\n",
    "   - Create production-ready predictors\n",
    "   - Export models for sharing\n",
    "   - Document projects professionally\n",
    "\n",
    "### Conceptual Understanding\n",
    "- How transformers work for NLP tasks\n",
    "- Extractive vs. generative QA\n",
    "- Transfer learning and fine-tuning\n",
    "- Evaluation methodology for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af0896",
   "metadata": {},
   "source": [
    "## ðŸš¦ Project Status Checklist\n",
    "\n",
    "Use this checklist to track your progress:\n",
    "\n",
    "### Setup\n",
    "- [ ] Install dependencies (`pip install -r requirements.txt`)\n",
    "- [ ] Verify dataset files exist in `archive/`\n",
    "- [ ] Test imports in notebooks\n",
    "\n",
    "### Part 1: Data Understanding\n",
    "- [ ] Run 01_data_exploration.ipynb\n",
    "- [ ] Run 02_tokenizer_testing.ipynb\n",
    "- [ ] Understand SQuAD format and tokenization\n",
    "\n",
    "### Part 2: Preprocessing\n",
    "- [ ] Run 03_data_validation.ipynb\n",
    "- [ ] Verify extraction accuracy >90%\n",
    "- [ ] Test DataLoader batching\n",
    "\n",
    "### Part 3: Training\n",
    "- [ ] Run 04_model_training.ipynb\n",
    "- [ ] Complete 3 epochs of training (2-3 hours)\n",
    "- [ ] Save checkpoint to `checkpoints/best_model.pt`\n",
    "\n",
    "### Part 4: Evaluation\n",
    "- [ ] Run 05_evaluation_analysis.ipynb\n",
    "- [ ] Achieve EM >80% and F1 >85%\n",
    "- [ ] Review error analysis\n",
    "\n",
    "### Part 5: Deployment\n",
    "- [ ] Run 06_deployment.ipynb\n",
    "- [ ] Test Gradio interface locally\n",
    "- [ ] Generate standalone app.py\n",
    "\n",
    "### Documentation\n",
    "- [ ] Review README.md\n",
    "- [ ] Understand project structure\n",
    "- [ ] Document any custom modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36b5eb",
   "metadata": {},
   "source": [
    "## ðŸ”— Useful Resources\n",
    "\n",
    "### Documentation\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers)\n",
    "- [SQuAD Dataset](https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "- [BERT Paper](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "### Tutorials\n",
    "- [Question Answering with BERT](https://huggingface.co/transformers/task_summary.html#question-answering)\n",
    "- [Fine-tuning BERT Tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
    "\n",
    "### Tools\n",
    "- [Gradio Documentation](https://gradio.app/docs/)\n",
    "- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "- [TensorBoard Guide](https://www.tensorflow.org/tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54dfd31",
   "metadata": {},
   "source": [
    "## ðŸ’» Next Steps\n",
    "\n",
    "### Immediate Actions\n",
    "1. **If starting fresh:** Begin with `01_data_exploration.ipynb`\n",
    "2. **If resuming:** Check which notebooks you've completed\n",
    "3. **If trained:** Test deployment with `06_deployment.ipynb`\n",
    "\n",
    "### Advanced Enhancements\n",
    "- Experiment with different BERT variants (RoBERTa, ALBERT, DistilBERT)\n",
    "- Try SQuAD v2.0 (includes unanswerable questions)\n",
    "- Implement answer re-ranking\n",
    "- Add multi-language support\n",
    "- Deploy to cloud (AWS, GCP, HuggingFace Spaces)\n",
    "- Create REST API with FastAPI\n",
    "\n",
    "### Optimization Ideas\n",
    "- Hyperparameter tuning (learning rate, batch size)\n",
    "- Data augmentation techniques\n",
    "- Ensemble multiple models\n",
    "- Knowledge distillation for smaller models\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

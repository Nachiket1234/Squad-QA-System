{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9744c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04763b",
   "metadata": {},
   "source": [
    "## 1. Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aeffec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded BERT tokenizer\n",
      "Vocab size: 30,522\n",
      "Model max length: 512\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"✓ Loaded BERT tokenizer\")\n",
    "print(f\"Vocab size: {tokenizer.vocab_size:,}\")\n",
    "print(f\"Model max length: {tokenizer.model_max_length:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d724fb",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data from SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c31d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "================================================================================\n",
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "\n",
      "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper sta...\n",
      "\n",
      "Answer: 'Saint Bernadette Soubirous'\n",
      "Answer starts at character position: 515\n",
      "\n",
      "Verification: 'Saint Bernadette Soubirous'\n"
     ]
    }
   ],
   "source": [
    "# Load a sample from the training set\n",
    "with open('../archive/train-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Extract a sample question-context pair\n",
    "sample_article = train_data['data'][0]\n",
    "sample_paragraph = sample_article['paragraphs'][0]\n",
    "sample_qa = sample_paragraph['qas'][0]\n",
    "\n",
    "context = sample_paragraph['context']\n",
    "question = sample_qa['question']\n",
    "answer_text = sample_qa['answers'][0]['text']\n",
    "answer_start = sample_qa['answers'][0]['answer_start']\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"\\nContext: {context[:200]}...\")\n",
    "print(f\"\\nAnswer: '{answer_text}'\")\n",
    "print(f\"Answer starts at character position: {answer_start}\")\n",
    "print(f\"\\nVerification: '{context[answer_start:answer_start+len(answer_text)]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a5dce",
   "metadata": {},
   "source": [
    "## 3. Basic Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343bdefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question tokens:\n",
      "['to', 'whom', 'did', 'the', 'virgin', 'mary', 'allegedly', 'appear', 'in', '1858', 'in', 'lou', '##rdes', 'france', '?']\n",
      "\n",
      "Number of tokens: 15\n"
     ]
    }
   ],
   "source": [
    "# Tokenize question only\n",
    "question_tokens = tokenizer.tokenize(question)\n",
    "print(\"Question tokens:\")\n",
    "print(question_tokens)\n",
    "print(f\"\\nNumber of tokens: {len(question_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da13c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sample tokens:\n",
      "['architectural', '##ly', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'\", 's', 'gold', 'dome', 'is', 'a', 'golden']\n",
      "\n",
      "Number of tokens: 21\n"
     ]
    }
   ],
   "source": [
    "# Tokenize context only (first 100 chars)\n",
    "context_sample = context[:100]\n",
    "context_tokens = tokenizer.tokenize(context_sample)\n",
    "print(\"Context sample tokens:\")\n",
    "print(context_tokens)\n",
    "print(f\"\\nNumber of tokens: {len(context_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716a9fc",
   "metadata": {},
   "source": [
    "## 4. Question-Context Pair Tokenization\n",
    "\n",
    "For QA, we need to tokenize question and context together with special format:\n",
    "```\n",
    "[CLS] question [SEP] context [SEP]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b52f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding keys: KeysView({'input_ids': tensor([[  101,  2000,  3183,  2106,  1996,  6261,  2984,  9382,  3711,  1999,\n",
      "          8517,  1999, 10223, 26371,  2605,  1029,   102,  6549,  2135,  1010,\n",
      "          1996,  2082,  2038,  1037,  3234,  2839,  1012, 10234,  1996,  2364,\n",
      "          2311,  1005,  1055,  2751,  8514,  2003,  1037,  3585,  6231,  1997,\n",
      "          1996,  6261,  2984,  1012,  3202,  1999,  2392,  1997,  1996,  2364,\n",
      "          2311,  1998,  5307,  2009,  1010,  2003,  1037,  6967,  6231,  1997,\n",
      "          4828,  2007,  2608,  2039, 14995,  6924,  2007,  1996,  5722,  1000,\n",
      "          2310,  3490,  2618,  4748,  2033, 18168,  5267,  1000,  1012,  2279,\n",
      "          2000,  1996,  2364,  2311,  2003,  1996, 13546,  1997,  1996,  6730,\n",
      "          2540,  1012,  3202,  2369,  1996, 13546,  2003,  1996, 24665, 23052,\n",
      "          1010,  1037, 14042,  2173,  1997,  7083,  1998,  9185,  1012,  2009,\n",
      "          2003,  1037, 15059,  1997,  1996, 24665, 23052,  2012, 10223, 26371,\n",
      "          1010,  2605,  2073,  1996,  6261,  2984, 22353,  2135,  2596,  2000,\n",
      "          3002, 16595,  9648,  4674,  2061, 12083,  9711,  2271,  1999,  8517,\n",
      "          1012,  2012,  1996,  2203,  1997,  1996,  2364,  3298,  1006,  1998,\n",
      "          1999,  1037,  3622,  2240,  2008,  8539,  2083,  1017, 11342,  1998,\n",
      "          1996,  2751,  8514,  1007,  1010,  2003,  1037,  3722,  1010,  2715,\n",
      "          2962,  6231,  1997,  2984,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})\n",
      "\n",
      "Input IDs shape: torch.Size([1, 384])\n",
      "Attention mask shape: torch.Size([1, 384])\n",
      "Token type IDs shape: torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize question and context as a pair\n",
    "encoding = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=384,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "print(\"Encoding keys:\", encoding.keys())\n",
    "print(f\"\\nInput IDs shape: {encoding['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {encoding['attention_mask'].shape}\")\n",
    "print(f\"Token type IDs shape: {encoding['token_type_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da241038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded tokens (first 300 chars):\n",
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] architecturally, the school has a catholic character. atop the main building ' s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ  ...\n"
     ]
    }
   ],
   "source": [
    "# Decode to see the tokenized text\n",
    "decoded = tokenizer.decode(encoding['input_ids'][0])\n",
    "print(\"Decoded tokens (first 300 chars):\")\n",
    "print(decoded[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443ca68",
   "metadata": {},
   "source": [
    "## 5. Understanding Token Type IDs\n",
    "\n",
    "Token type IDs distinguish question tokens (0) from context tokens (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b616e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token | Type (0=Question, 1=Context)\n",
      "==================================================\n",
      "  0. [CLS]           | 0 (QUESTION)\n",
      "  1. to              | 0 (QUESTION)\n",
      "  2. whom            | 0 (QUESTION)\n",
      "  3. did             | 0 (QUESTION)\n",
      "  4. the             | 0 (QUESTION)\n",
      "  5. virgin          | 0 (QUESTION)\n",
      "  6. mary            | 0 (QUESTION)\n",
      "  7. allegedly       | 0 (QUESTION)\n",
      "  8. appear          | 0 (QUESTION)\n",
      "  9. in              | 0 (QUESTION)\n",
      " 10. 1858            | 0 (QUESTION)\n",
      " 11. in              | 0 (QUESTION)\n",
      " 12. lou             | 0 (QUESTION)\n",
      " 13. ##rdes          | 0 (QUESTION)\n",
      " 14. france          | 0 (QUESTION)\n",
      " 15. ?               | 0 (QUESTION)\n",
      " 16. [SEP]           | 0 (QUESTION)\n",
      " 17. architectural   | 1 (CONTEXT)\n",
      " 18. ##ly            | 1 (CONTEXT)\n",
      " 19. ,               | 1 (CONTEXT)\n",
      " 20. the             | 1 (CONTEXT)\n",
      " 21. school          | 1 (CONTEXT)\n",
      " 22. has             | 1 (CONTEXT)\n",
      " 23. a               | 1 (CONTEXT)\n",
      " 24. catholic        | 1 (CONTEXT)\n",
      " 25. character       | 1 (CONTEXT)\n",
      " 26. .               | 1 (CONTEXT)\n",
      " 27. atop            | 1 (CONTEXT)\n",
      " 28. the             | 1 (CONTEXT)\n",
      " 29. main            | 1 (CONTEXT)\n"
     ]
    }
   ],
   "source": [
    "# Display first 30 tokens with their types\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "token_type_ids = encoding['token_type_ids'][0].tolist()\n",
    "\n",
    "print(\"Token | Type (0=Question, 1=Context)\")\n",
    "print(\"=\"*50)\n",
    "for i in range(min(30, len(tokens))):\n",
    "    token = tokens[i]\n",
    "    token_type = token_type_ids[i]\n",
    "    segment = \"QUESTION\" if token_type == 0 else \"CONTEXT\"\n",
    "    print(f\"{i:3d}. {token:15s} | {token_type} ({segment})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2918b9d",
   "metadata": {},
   "source": [
    "## 6. Offset Mappings - The Key to Answer Span Conversion\n",
    "\n",
    "Offset mappings show which character positions each token corresponds to in the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8345fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset mapping shape: torch.Size([176, 2])\n",
      "\n",
      "First 20 offset mappings (char start, char end):\n",
      "tensor([[ 0,  0],\n",
      "        [ 0,  2],\n",
      "        [ 3,  7],\n",
      "        [ 8, 11],\n",
      "        [12, 15],\n",
      "        [16, 22],\n",
      "        [23, 27],\n",
      "        [28, 37],\n",
      "        [38, 44],\n",
      "        [45, 47],\n",
      "        [48, 52],\n",
      "        [53, 55],\n",
      "        [56, 59],\n",
      "        [59, 63],\n",
      "        [64, 70],\n",
      "        [70, 71],\n",
      "        [ 0,  0],\n",
      "        [ 0, 13],\n",
      "        [13, 15],\n",
      "        [15, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with offset mappings\n",
    "encoding_with_offsets = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    truncation=True,\n",
    "    max_length=384,\n",
    "    return_offsets_mapping=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "offset_mapping = encoding_with_offsets['offset_mapping'][0]\n",
    "print(f\"Offset mapping shape: {offset_mapping.shape}\")\n",
    "print(f\"\\nFirst 20 offset mappings (char start, char end):\")\n",
    "print(offset_mapping[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c66b9c",
   "metadata": {},
   "source": [
    "## 7. Converting Character Positions to Token Positions\n",
    "\n",
    "This is crucial for finding the answer span in tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e198ac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'Saint Bernadette Soubirous'\n",
      "Character position: 515 to 541\n",
      "\n",
      "Token position: 130 to 137\n"
     ]
    }
   ],
   "source": [
    "def find_answer_span(answer_start_char, answer_text, offset_mapping, sequence_ids):\n",
    "    \"\"\"\n",
    "    Convert character-level answer position to token-level positions.\n",
    "    \n",
    "    Args:\n",
    "        answer_start_char: Character position where answer starts\n",
    "        answer_text: The answer text\n",
    "        offset_mapping: Tensor of (start, end) character offsets for each token\n",
    "        sequence_ids: List indicating which tokens belong to context (1) vs question (0)\n",
    "    \n",
    "    Returns:\n",
    "        start_token_idx: Token index where answer starts\n",
    "        end_token_idx: Token index where answer ends\n",
    "    \"\"\"\n",
    "    answer_end_char = answer_start_char + len(answer_text)\n",
    "    \n",
    "    # Find start token\n",
    "    start_token_idx = None\n",
    "    for idx, (start, end) in enumerate(offset_mapping):\n",
    "        # Only consider context tokens (sequence_id == 1)\n",
    "        if sequence_ids[idx] == 1:\n",
    "            if start <= answer_start_char < end:\n",
    "                start_token_idx = idx\n",
    "                break\n",
    "    \n",
    "    # Find end token\n",
    "    end_token_idx = None\n",
    "    for idx, (start, end) in enumerate(offset_mapping):\n",
    "        if sequence_ids[idx] == 1:\n",
    "            if start < answer_end_char <= end:\n",
    "                end_token_idx = idx\n",
    "                break\n",
    "    \n",
    "    return start_token_idx, end_token_idx\n",
    "\n",
    "# Get sequence IDs to identify context tokens\n",
    "sequence_ids = encoding_with_offsets.sequence_ids(0)\n",
    "\n",
    "# Find answer span in tokens\n",
    "start_token, end_token = find_answer_span(\n",
    "    answer_start, \n",
    "    answer_text, \n",
    "    offset_mapping,\n",
    "    sequence_ids\n",
    ")\n",
    "\n",
    "print(f\"Answer: '{answer_text}'\")\n",
    "print(f\"Character position: {answer_start} to {answer_start + len(answer_text)}\")\n",
    "print(f\"\\nToken position: {start_token} to {end_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4628d1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification:\n",
      "Original answer: 'Saint Bernadette Soubirous'\n",
      "Decoded from tokens: 'saint bernadette soubirous'\n",
      "\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Verify by decoding the token span\n",
    "if start_token is not None and end_token is not None:\n",
    "    answer_token_ids = encoding_with_offsets['input_ids'][0][start_token:end_token+1]\n",
    "    decoded_answer = tokenizer.decode(answer_token_ids)\n",
    "    \n",
    "    print(\"Verification:\")\n",
    "    print(f\"Original answer: '{answer_text}'\")\n",
    "    print(f\"Decoded from tokens: '{decoded_answer}'\")\n",
    "    print(f\"\\nMatch: {answer_text.lower() in decoded_answer.lower()}\")\n",
    "else:\n",
    "    print(\"Could not find answer span in tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9e30c",
   "metadata": {},
   "source": [
    "## 8. Visualize Token Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb959caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens around the answer:\n",
      "================================================================================\n",
      "    125. mary                 tensor([488, 492])\n",
      "    126. reputed              tensor([493, 500])\n",
      "    127. ##ly                 tensor([500, 502])\n",
      "    128. appeared             tensor([503, 511])\n",
      "    129. to                   tensor([512, 514])\n",
      ">>> 130. saint                tensor([515, 520])\n",
      ">>> 131. bern                 tensor([521, 525])\n",
      ">>> 132. ##ade                tensor([525, 528])\n",
      ">>> 133. ##tte                tensor([528, 531])\n",
      ">>> 134. so                   tensor([532, 534])\n",
      ">>> 135. ##ub                 tensor([534, 536])\n",
      ">>> 136. ##iro                tensor([536, 539])\n",
      ">>> 137. ##us                 tensor([539, 541])\n",
      "    138. in                   tensor([542, 544])\n",
      "    139. 1858                 tensor([545, 549])\n",
      "    140. .                    tensor([549, 550])\n",
      "    141. at                   tensor([551, 553])\n",
      "    142. the                  tensor([554, 557])\n"
     ]
    }
   ],
   "source": [
    "# Show tokens around the answer\n",
    "if start_token is not None and end_token is not None:\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding_with_offsets['input_ids'][0])\n",
    "    \n",
    "    print(\"Tokens around the answer:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Show 5 tokens before and after\n",
    "    window_start = max(0, start_token - 5)\n",
    "    window_end = min(len(tokens), end_token + 6)\n",
    "    \n",
    "    for idx in range(window_start, window_end):\n",
    "        token = tokens[idx]\n",
    "        is_answer = start_token <= idx <= end_token\n",
    "        marker = \">>> \" if is_answer else \"    \"\n",
    "        print(f\"{marker}{idx:3d}. {token:20s} {offset_mapping[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860ecb8",
   "metadata": {},
   "source": [
    "## 9. Handling Long Contexts (Stride)\n",
    "\n",
    "When context exceeds max_length, we use stride to create overlapping windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d774dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      5\u001b[39m encoding_with_stride = tokenizer(\n\u001b[32m      6\u001b[39m     question,\n\u001b[32m      7\u001b[39m     long_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     padding=\u001b[33m'\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of chunks created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(encoding_with_stride[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEach chunk has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mencoding_with_stride\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStride (overlap): 128 tokens\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Example with a longer context\n",
    "long_context = context * 3  # Artificially create a long context\n",
    "\n",
    "# Tokenize with stride\n",
    "encoding_with_stride = tokenizer(\n",
    "    question,\n",
    "    long_context,\n",
    "    truncation='only_second',  # Only truncate context, not question\n",
    "    max_length=384,\n",
    "    stride=128,  # Overlap of 128 tokens between chunks\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding='max_length'\n",
    ")\n",
    "\n",
    "print(f\"Number of chunks created: {len(encoding_with_stride['input_ids'])}\")\n",
    "print(f\"\\nEach chunk has {encoding_with_stride['input_ids'][0].shape[0]} tokens\")\n",
    "print(f\"Stride (overlap): 128 tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f1f93",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ca62c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Concepts for BERT Tokenization in QA:\n",
      "\n",
      "1. **Special Token Format**: [CLS] question [SEP] context [SEP]\n",
      "\n",
      "2. **Token Type IDs**:\n",
      "   - 0 = question tokens\n",
      "   - 1 = context tokens\n",
      "\n",
      "3. **Offset Mappings**:\n",
      "   - Maps each token to its character position in original text\n",
      "   - Essential for converting answer_start (char) to token positions\n",
      "\n",
      "4. **Answer Span Conversion**:\n",
      "   - Character position (answer_start) → Token position (start_token_idx)\n",
      "   - Use offset_mapping to find which tokens contain the answer\n",
      "\n",
      "5. **Handling Long Contexts**:\n",
      "   - Use truncation='only_second' to preserve question\n",
      "   - Use stride for overlapping windows\n",
      "   - Set return_overflowing_tokens=True\n",
      "\n",
      "6. **Sequence IDs**:\n",
      "   - Use encoding.sequence_ids() to identify context vs question\n",
      "   - Important for ensuring answer is only in context portion\n",
      "\n",
      "Next Steps:\n",
      "- Build PyTorch Dataset that handles this tokenization\n",
      "- Implement answer span finding logic in batch processing\n",
      "- Create DataLoader for training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Key Concepts for BERT Tokenization in QA:\n",
    "\n",
    "1. **Special Token Format**: [CLS] question [SEP] context [SEP]\n",
    "\n",
    "2. **Token Type IDs**:\n",
    "   - 0 = question tokens\n",
    "   - 1 = context tokens\n",
    "\n",
    "3. **Offset Mappings**:\n",
    "   - Maps each token to its character position in original text\n",
    "   - Essential for converting answer_start (char) to token positions\n",
    "\n",
    "4. **Answer Span Conversion**:\n",
    "   - Character position (answer_start) → Token position (start_token_idx)\n",
    "   - Use offset_mapping to find which tokens contain the answer\n",
    "\n",
    "5. **Handling Long Contexts**:\n",
    "   - Use truncation='only_second' to preserve question\n",
    "   - Use stride for overlapping windows\n",
    "   - Set return_overflowing_tokens=True\n",
    "\n",
    "6. **Sequence IDs**:\n",
    "   - Use encoding.sequence_ids() to identify context vs question\n",
    "   - Important for ensuring answer is only in context portion\n",
    "\n",
    "Next Steps:\n",
    "- Build PyTorch Dataset that handles this tokenization\n",
    "- Implement answer span finding logic in batch processing\n",
    "- Create DataLoader for training\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
